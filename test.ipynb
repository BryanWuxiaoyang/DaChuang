{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda40184ef986494cbba194627aebfd1910",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ok\ncur page:  1\n"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#usage: 三个参数 1：起始页面 2：终止页面 3：目标股吧id\n",
    "\n",
    "#上证指数股吧 其他股吧更改list，后面内容即可，最后大括号用于控制页数\n",
    "#base_url = 'http://guba.eastmoney.com/list,zssh000001_{}.html'\n",
    "\n",
    "stkcd=np.load('stkcd.npy').tolist()\n",
    "stkcd=stkcd[:1]\n",
    "\n",
    "\n",
    "#records=[]\n",
    "#遍历页码\n",
    "start_page=1#int(sys.argv[1])\n",
    "end_page=2#int(sys.argv[2])\n",
    "#就是'http://guba.eastmoney.com/list,zssh000001_{}.html' 里面zssh000001部分，可以用其他代替\n",
    "\n",
    "\n",
    "#target=sys.argv[3]\n",
    "#base_url='http://guba.eastmoney.com/list,'+target+'_{}.html'\n",
    "\n",
    "for i in list(range(0,len(stkcd),500)):\n",
    "    k=1\n",
    "    df=pd.DataFrame()\n",
    "    for this_id in stkcd[i:i+500]:\n",
    "        base_url='http://guba.eastmoney.com/list,'+this_id+'_{}.html'\n",
    "        print('ok')\n",
    "        for page in list(range(start_page,end_page)):\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                print('cur page: ',page) \n",
    "                r=requests.get(base_url.format(page))\n",
    "                article_list = BeautifulSoup(r.content, 'lxml').find_all(class_='articleh normal_post')\n",
    "                item_count=0\n",
    "                #print('item_count: ')\n",
    "                for item in article_list:\n",
    "                    try:\n",
    "                        time.sleep(0.1)\n",
    "                        reads=item.find_all('span',class_='l1 a1')[0].get_text()\n",
    "                        #title=item.find_all('span',class_='l3 a3')[0].a['title']\n",
    "                        href='http://guba.eastmoney.com'+item.find_all('span',class_='l3 a3')[0].a['href']\n",
    "                        detail=BeautifulSoup(requests.get(href).content, \"lxml\")\n",
    "                        title=detail.find_all('div',id='zwconttbt')[0].get_text()\n",
    "                        data=json.loads(detail.find_all(class_='data')[0]['data-json'])\n",
    "                        user_id=data['user_id']\n",
    "                        if user_id=='':\n",
    "                            user_id=-1\n",
    "                        else:\n",
    "                            user_id=int(user_id)\n",
    "                        #user_name=data['user_nickname']\n",
    "                        star=data['user_influ_level']\n",
    "                        time_stamp=detail.find_all(class_='zwfbtime')[0].get_text()\n",
    "                        time_stamp=re.sub(r'[\\u4e00-\\u9fa5a-zA-Z]','',time_stamp)\n",
    "                        #大部分历史数据不用计算哈希了，最近的可能爬到重复了的再计算\n",
    "                        #record['id']=hash(user_name+title[:5])\n",
    "                        #record['href']=href\n",
    "                        record={}\n",
    "                        #record['stkcd']=this_id\n",
    "                        record['time']=time_stamp\n",
    "                        record['read_count']=reads\n",
    "                        record['user_id']=user_id\n",
    "                        #record['name']=user_name\n",
    "                        record['star']=star\n",
    "                        record['content']=title\n",
    "                        #jInfo=json.dumps(record,ensure_ascii=False)\n",
    "                        #print(record)\n",
    "                        df=df.append(pd.DataFrame(record,index=[this_id]))\n",
    "                        #print(df)\n",
    "                        #print (\"\\r \".format(item_count)+str(item_count), end=\"\")\n",
    "                        #item_count+=1\n",
    "                        #break\n",
    "                    except Exception as err:\n",
    "                        pass\n",
    "                        #print(err)\n",
    "                    \n",
    "            except Exception as err:\n",
    "                pass\n",
    "                #print(err)\n",
    "    #df.to_csv('./comment'+str(k)+'.csv' )\n",
    "    k+=1   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>read_count</th>\n      <th>user_id</th>\n      <th>star</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>002833</td>\n      <td>2020-02-23 15:34:14</td>\n      <td>314</td>\n      <td>6466074627920430</td>\n      <td>2</td>\n      <td>\\r\\n就留了一手，等涨到五十七着卖                            ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-02-21 19:55:57</td>\n      <td>800</td>\n      <td>5121085475613572</td>\n      <td>4</td>\n      <td>\\r\\n到五日线了，忘了买                                 ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-02-17 13:34:56</td>\n      <td>7654</td>\n      <td>4515014304226172</td>\n      <td>6</td>\n      <td>\\r\\n公司深度：内外兼修抢占新一轮板式家具扩产周期                    ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-02-21 14:10:48</td>\n      <td>1009</td>\n      <td>8283094364530000</td>\n      <td>0</td>\n      <td>\\r\\n天哪，发生什么事了，突然下这么厉害。是不是周末又要有什么不利消息了。        ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-02-21 13:56:15</td>\n      <td>796</td>\n      <td>3991625223319608</td>\n      <td>0</td>\n      <td>\\r\\n等待你的跌停!                                   ...</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-01-15 18:45:34</td>\n      <td>1311</td>\n      <td>6696113366419406</td>\n      <td>7</td>\n      <td>\\r\\n财务数据这么好的股票在两市绝对是凤毛麟角的存在                   ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-01-15 14:40:00</td>\n      <td>760</td>\n      <td>3530365714997088</td>\n      <td>2</td>\n      <td>\\r\\n走了我受够你了                                   ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-01-15 14:36:36</td>\n      <td>787</td>\n      <td>4977375533973186</td>\n      <td>2</td>\n      <td>\\r\\n大伙坐稳了吗？马上起飞啦，                             ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-01-15 13:22:34</td>\n      <td>1075</td>\n      <td>4860124836266016</td>\n      <td>3</td>\n      <td>\\r\\n这个时候庄家稳住股价，等待接盘侠们                         ...</td>\n    </tr>\n    <tr>\n      <td>002833</td>\n      <td>2020-01-15 11:33:06</td>\n      <td>806</td>\n      <td>3678065025084944</td>\n      <td>2</td>\n      <td>\\r\\n出了，久横必暴跌洗盘                                ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 5 columns</p>\n</div>",
      "text/plain": "                         time read_count           user_id  star  \\\n002833   2020-02-23 15:34:14         314  6466074627920430     2   \n002833   2020-02-21 19:55:57         800  5121085475613572     4   \n002833   2020-02-17 13:34:56        7654  4515014304226172     6   \n002833   2020-02-21 14:10:48        1009  8283094364530000     0   \n002833   2020-02-21 13:56:15         796  3991625223319608     0   \n...                       ...        ...               ...   ...   \n002833   2020-01-15 18:45:34        1311  6696113366419406     7   \n002833   2020-01-15 14:40:00         760  3530365714997088     2   \n002833   2020-01-15 14:36:36         787  4977375533973186     2   \n002833   2020-01-15 13:22:34        1075  4860124836266016     3   \n002833   2020-01-15 11:33:06         806  3678065025084944     2   \n\n                                                  content  \n002833  \\r\\n就留了一手，等涨到五十七着卖                            ...  \n002833  \\r\\n到五日线了，忘了买                                 ...  \n002833  \\r\\n公司深度：内外兼修抢占新一轮板式家具扩产周期                    ...  \n002833  \\r\\n天哪，发生什么事了，突然下这么厉害。是不是周末又要有什么不利消息了。        ...  \n002833  \\r\\n等待你的跌停!                                   ...  \n...                                                   ...  \n002833  \\r\\n财务数据这么好的股票在两市绝对是凤毛麟角的存在                   ...  \n002833  \\r\\n走了我受够你了                                   ...  \n002833  \\r\\n大伙坐稳了吗？马上起飞啦，                             ...  \n002833  \\r\\n这个时候庄家稳住股价，等待接盘侠们                         ...  \n002833  \\r\\n出了，久横必暴跌洗盘                                ...  \n\n[80 rows x 5 columns]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}